import requests
from lxml import etree

class Spider:
    def __init__(self) -> None:
        # 文件保存的路径
        self.__file="./goods1.txt"
        # 要采集的url（放到服务器上跑会快很多！！！，但需要修改为shopxo内网地址）
        # 注意网址一定不要复制错
        self.__site="http://172.18.0.118/index.php?s=/index/goods/index/id/{}.html"

        # 外网
        # self.__site="http://39.106.159.66/index.php?s=/index/goods/index/id/{}.html"
        # 要采集的最大的id=>1278
        self.__maxID=1278
        pass
    # 采集方法
    def __spider(self,url):
        header={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'}
        # 发起GET请求
        response=requests.get(url,headers=header)
        # 判断：1. 状态码是否为200；2. 页面中是否包含特定的关键词
        if response.status_code==200:
            if "资源不存在或已被删除" in response.text:
                print(f"请求的{url}没有商品!")
                return None
            else:
                # response -> html
                html=etree.HTML(response.text)

                # 定位页面元素：名称、价格（销售价）、浏览量、销量、库存
                # 商品名称
                name=html.xpath('//h1[@class="detail-title am-margin-bottom-xs"]/text()')[0].strip()
                # 价格
                price=html.xpath('//b[@class="goods-price"]/text()')[0]
                tm_counts=html.xpath('//span[@class="tm-count"]/text()')
                # 浏览量
                view_count=tm_counts[1]
                # 销量
                sale_count=tm_counts[0]
                # 库存
                stock=html.xpath('//span[@class="stock"]/text()')[0]

                result=f"{name},{price},{view_count},{sale_count},{stock}\n"

                return result
        else:
            print(f"请求的{url}出现问题，状态码为：{response.status_code}")

    def run(self):
        # 打开文件
        file=open(self.__file,"a+",encoding="utf-8")
        for num in range(1,self.__maxID+1):
            result=self.__spider(self.__site.format(num))
            if result:
                # 加入商品id
                content=str(num)+","+result
                # 写出到文件
                file.write(content)
            else:
                continue
        file.close()
        return


# 程序入口
if __name__=="__main__":
    spider=Spider()
    spider.run()